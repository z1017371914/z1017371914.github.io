

## 中断

### 含义

中断是CPU在执行程序的过程中，暂停当前的程序，去执行新的程序，结束后再执行之前的程序

### 分类

#### 内部异常中断

硬件故障引发的中断

#### 软件中断

程序执行了中断指令而进入的中断(系统调用)

#### 外部中断

由外部设备引起的中断

### 优先级

机器错误->时钟->磁盘->网络设备->终端设备->软件中断

## 系统调用

### 含义

程序一般是在用户态下运行，当需要进行某些较危险的服务，比如读写文件，创建文件，打开设备等，不应当由用户来管理操作，而应当由操作系统来负责帮忙。因此需要从用户态进入到核心态，让操作系统调用核心态的函数来帮助用户执行特殊操作

### 作用

保证了系统的安全性与稳定性，将危险的操作权限从用户手中剥夺

### 状态

系统调用只有在进入核心态时才能完成

### 调用过程

比如执行write("abc"):

>1.接收到参数
>
>2.用户态下执行陷入指令
>
>3.进入核心态，产生系统中断，操作系统完成相关操作
>
>4.返回到程序

总结：用户态下发送系统调用请求->操作系统进入核心态进行相关服务->返回用户态继续执行程序

## 进程

### 含义

进程是程序执行的一个基本单位，是申请操作系统资源的最小单位。

### 组成

PCB，程序代码段，数据段

可见除了程序与数据，进程还需要PCB记录进程的信息

#### PCB

##### 基本组成

1.进程的信息：

端口号：PID； 用户ID：UID；
进程的优先级；进程的状态

2.进程的资源：

程序段指针；数据段指针；

鼠标键盘等(可能有)

3.各种寄存器的信息：存放指令，数据等

### 特征

>1.动态性：进程的产生,执行，消亡是动态的
>
>2.并发性：内存中有多个进程，进程是并发执行的
>
>3.独立性：进程是资源分配、调度的基本单位。
>
>4.异步性：进程按照各自独立，不可预知的速度机进行。

要解决异步性，就要通过进程同步来解决

### 状态

>1.就绪态：进程创建完毕，并分配了系统资源，等待时间片的分配
>
>2.运行态：就绪态获得时间片，开始执行进程
>
>3.阻塞态：进程在运行态时发出I/O请求，需要等待，进入阻塞态。
>
>​				 阻塞态获得I/O后进入就绪态
>
>4.创建态: 进程创建，初始化了PCB。等待分配资源进入就绪态
>
>5.终止态：进程在运行态时执行结束，进入终止态

### 状态切换

![image](https://tvax4.sinaimg.cn/large/0085EwgIgy1goc8ac3yfhj30aj073abs.jpg)

### 原语

原语执行期间不允许发生中断，保证程序能够完成的执行。

如何实现的？原语执行前，执行了关中断指令，不允许操作系统发生中断，执行后执行开中断指令，允许操作系统发生中断

可见原语一定要在核心态下才能执行

#### 进程控制原语

进程控制原语的共同操作：

>1.更新PCB的信息
>
>2.将PCB分配到合适的队列
>
>3.分配系统资源

##### 创建原语

使得进程从 无->创建态->就绪态

操作：申请PCB，初始化PCB，为进程分配资源，将PCB插入到就绪队列

##### 撤消原语

使得进程从运行态->终止态

操作：

>1.剥夺处理机
>
>2.终止其所有子进程
>
>3.回收系统资源
>
>4.删除PCB

##### 阻塞原语

使得进程从运行态->阻塞态

操作：

>1.保存进程的现场
>
>2.更新PCB中进程状态为阻塞态
>
>3.将PCB插入到阻塞队列

##### 唤醒原语

使得进程从阻塞态->就绪态

操作：

>1.将PCB插入到就绪队列
>
>2.更新PCB的进程状态为就绪态

##### 切换原语

将处理机正在执行的切换成另一进程

>1.保存当前进程的信息
>
>2.将当前进程移入阻塞队列，更新PCB中进程的状态为阻塞态
>
>3.更新新的进程的PCB，为其分配系统资源

### 进程调度

#### 上下文切换

含义：进行或线程进行切换时，需要保存上文，加载下文。

线程共享进程的资源，因此线程切换时，上下文切换的开销是要小于进程切换的上下文的。因为线程切换时快表和高速缓存cache不会失效，而进程是会失效的

#### 调度种类

>1.高级调度：将作业存入到内存中执行
>
>2.中级调度：在内存，外村段换取进行进程切换
>
>3.低级调度：进程调度，允许就绪队列中的某个进程进入CPU执行

### 非抢占式调度

进程一直占有CPU执行，直到此进程遇到某时间阻塞时，才会将处理机分配给其他进程

1.FCFS

2.SJF

3.HRN

### 抢占式调度

1.RR

2.优先级调度

强行让正在执行的进程暂停，将处理机分配给其他进程

### 进程的调度算法

>1.FCFS先来先服务。按顺序执行，不可抢占，不会导致饥饿，但不利于排在长进程后的短进程
>
>2.SJF短作业优先调度算法。当前时间最短的进程优先执行，非抢占式，但不利于长进程，可能会导致长进程的饥饿现象
>
>3.HRRN高响应比优先调度算法。响应比（等待时间+运行时间）/运行时间。非抢占式算法，不会导致饥饿
>
>4.Round-Robin时间盘轮转调度算法。规定时间片的长度，按就绪队列中的顺序来分配时间片，时间一到马上剥夺走。是可抢占式的，缺点是切换频繁，系统开销会很大，对于进程的紧急程度也不区分。不会导致饥饿
>
>5.优先级调度算法。每次执行优先级最高的。是可抢占的，会导致饥饿
>
>6.多级反馈队列调度算法。建立优先级不同的队列，在每个队列上使用不同的调度算法

### 进程通信

1.消息传递

2.共享存储

3.同步



#### 消息传递

1.管道

2.FIFO(命名管道)

3.消息队列

##### 管道

>采用半双工，可双向通信，但同一时间，只能单向通信
>
>要想实现管道同时通信，必须要设置两个管道
>
>特点：0读1写
>
>1.写端写入时，读端阻塞，无法读取
>
>2.写端写入结束，写端阻塞，读端可读
>
>3.读端读去时，写端阻塞，无法写入
>
>4.读端读取结束，读端阻塞，写端可写

##### FIFO(命名管道)

>命名管道解决了管道执行在父子之间通信的问题，存储在文件系统中，使得所有进程都可以通过路径名来访问命名管道。
>
>特点：
>
>1.先进先出原则
>
>2.可用于所有进程间的通信

##### 消息队列

>进程向另一进程发送数据块的方法，每一数据块都含有类型，但每一数据块都有长度限制。
>
>特点：
>
>1.消息队列存储在内存中
>
>2.消息队列由链表组合
>
>3.消息队列既可以先进先出的读取，也可以按类型来读取

#### 共享存储

含义：在内存中开辟一段空间，使得进程都可以访问该空间，

特点：进程对该空间的访问是互斥的

#### 同步

1.互斥量

2.条件变量

3.读写锁

4.文件和写记录锁

5.信号量

### 父进程与子进程

>子进程是系统调用fork产生的。
>
>调用fork后，父子进程会在不同的内存空间执行，子进程几乎是父进程的拷贝版本。
>
>早期的操作系统中，fork时，子进程确实全盘复制了父进程的所有内容，这会导致系统开销比较大。
>
>现在fork()时不会复制，只有当内存发生修改时，才会发生数据的复制(copy-on-write)
>
>copy-on-write：
>
>1.父子进程共享了相同的物理空间地址
>
>2.父子进程对内存进行修改时，共享内存会以页为单位进行拷贝。父进程保留原来的物理空间，子进程拷贝新的物理空间

### 进程同步

##### 临界资源与临界区

对于临界资源的访问必须是互斥的

>1.进入区：临界区是否可访问，可访问就进入，不可访问就被阻塞
>
>2.临界区：占有某些互斥资源进行操作
>
>3.退出区：清除用户占用的标志
>
>4.剩余区：和临界区不相关的代码

##### 信号量

1.实现进程互斥

```c
semaphore mutex=1;//定义互斥信号量

P1(){
    P(mutex);//访问临界区，先用PV操作中的P上锁
    临界区代码;
    V(mutex);//解锁，资源数+1
}

P2(){
    P(mutex);//访问临界区，先用PV操作中的P上锁
    临界区代码;
    V(mutex);//解锁，资源数+1
}

/**
执行P操作时会使得临界资源-1，如果资源数小于零，会自动将进程阻塞进行等待
从而达到了进程互斥的目的
*/
```

2.实现进程同步

前趋代码+V操作。

P操作+后继代码

```c
/**
假设必须先执行code2才能执行code4.
用下面的方式就实现了进程同步
*/
semaphore S=0;
P1(){
    code1;
    code2;
    V(S);//S+=1,此时S=1
    code3;
}
P2(){
    P(S);//S-=1,此时S=0
    code4;
    code5;
}
```

3.生产者-消费者问题

PPVV

```c
semaphore mutex=1;//互斥信号量
semaphore empty=n;//同步信号量，指向缓冲区空闲的数量
semaphore full=0;//同步信号量，指向缓冲区非空的数量

producer(){
    while(1){
        ...//生产产品
		P(empty);//empty-1,消耗一个空闲的数量
        P(mutex);//mutex-1,与consumer实现进程互斥
        ...//产品放入缓冲区
        v(mutex);
        V(full);
    }
}

consumer(){
    while(1){
        P(full);//full-1
        P(mutex);//mutex-1,与producer实现进程互斥
        ...//取出一产品
        V(mutex);//解锁
        V(empty);//empty+1
    }
}
```

##### 锁

>1.互斥锁：同一时间只能有一个线程访问互斥锁的数据
>
>2.自旋锁：用户一直等待对上了自旋锁的资源，直到锁结束了马上占有
>
>3.读写锁：将用户分成读写操作。读操作是共享的，但同一时间只能有一用户进行写操作，而且不能同时有读者，写者
>
>4.阻塞锁：将线程设成阻塞态，当特定条件时，才能进入就绪态
>
>5.可重入锁：一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法，而无需重新获得锁.对于不同线程，作用相当于互斥锁
>
>6.公平锁：按照线程的等待顺序，分配锁的拥有权
>
>7.非公平锁：不考虑排队问题，直接申请锁的拥有权。申请失败就进入到队尾等待
>
>8.悲观锁(synchronized)：每步操作都假设会发生冲突，因此在取数据时，会上锁，其他的线程只能等待。
>
>9.乐观锁：假设不会发生冲突，只在提交操作时检查是否违反数据的完整性。乐观锁不能解决脏读问题

##### 死锁

四个条件

>1.互斥使用
>
>2.循环等待
>
>3.请求与保持
>
>4.不剥夺

##### CAS

比较与交换。先将内存中的某个值进行存储，称为旧值。将旧值进行一系列操作得到新值。然后比较旧值与内存中旧值是否相等，相等的话将内存中的旧值换成新值，否则不改变内存的值

## 线程

### 含义

线程是操作系统调度的最小单位，线程包含在进程之中，是进程中实际运行的单位

### 组成

程序段，数据段，TCB(和PCB类似)

### 特点

1.可并发执行

2.共享同一进程的资源

## 内存

### 扩容

主存不会很大，但用户进程往往需要很多的空间，这就需要进行特定操作来扩容

#### 覆盖

将用户空间分成固定区和覆盖区。经常使用的数据放在固定区，准备使用的数据放在覆盖区，其他字段放在外存里。

#### 交换

将等待的进程从内存中移到辅存，将就绪的进程从辅存中移入内存。

### 连续分配

分配内存空间给进程。

分配方式如下：

#### 单一连续分配

将内存分配用户区和系统区。系统区只能由操作系统来使用。

用户区中只有一道程序，然后利用覆盖技术完成这个程序。

优点：

1.不需要进行内存保护，因为只有一个程序；

2.实现简单

3.不会产生外部碎片(未分配的区域剩余空间太小，无法再分配)

缺点：

1.只能处理单道程序，效率低下

2.会产生内存碎片(已分配的区域有间隙，无法分配)

#### 固定分区连续分配

用于多道程序处理。当有空闲的分区时，就从外存的就绪队列中取出，放入到分区中执行。

##### 等大小分区

![image](https://tvax2.sinaimg.cn/large/0085EwgIgy1gof5og7mhbj304t09p3yj.jpg)

可能会因为作业需要容量过大，无法放入，只能使用覆盖技术。

作业比较小时，利用率会很低。

##### 自定义分区

![image](https://tva4.sinaimg.cn/large/0085EwgIgy1gof5oq9p0qj305p09qmx7.jpg)

较为灵活的分配。

但也不可避免的存在内存碎片。

#### 动态分区分配

在进程装入内存时，动态的建立分区。

![image](https://tvax2.sinaimg.cn/large/0085EwgIgy1gof5w69lsuj30oa0h6q5j.jpg)

动态分区非常容易出现外部碎片。当碎片越来越多，在野无法分配时，就需要通过**紧凑**来处理外部碎片。但是紧凑的开销非常大：需要对进程移动和整理，需要更改都重定位寄存器。

##### 动态分区分配算法

###### 首次适应(First Fit)

按内存地址进行查找，找到第一个大小满足自己的分区。

一般来说是最大的策略。但是开销比较大，每次都要经过容量较小的分区慢慢查找到适合自己的。临近算法改进了这一点

###### 最佳适应(Best Fit)

按照分区空闲的大小递增的顺序进行查找，选择第一个适合自己的。

通常效率是最垃圾的。会产生很多的外部碎片。

###### 最坏适应(Worst Fit)

挑选系统当前最大的分区。这将内存的大容量分区都占有了，到时后面越来越难分配分区给需要容量较大的进程

###### 临近适应(Next Fit)

是首次适应算法的改进版本。从上一次查找的位置往下继续查找

### 非连续分配

连续分配对内存的要求比较高。如果没有足够大的连续内存，依旧是很难执行程序。于是有了非连续分配内存。

非连续分配：

**1.分页存储**

**2.分段存储**

#### 分页存储

##### 基本概念

分页的思想：将主存分成大小相等的块，把进程也按块进行划分，进程申请内存时，按照块为单位进行申请。

这样，只有在最后一个块中，进程通过分块占有，才会产生内部碎片(也叫页内碎片)。

页：进程中的块。

页框：内存中的块。页面大小为2的整数幂，太大会使内存碎片增多，太小会导致页表过长，占用内存开销大，地址转换时的换入换出开销大。

块：外存中的块

页表：建立了页和物理地址的映射关系。结构：页号+物理地址块号

##### 基本分页存储

![image](https://tvax1.sinaimg.cn/large/0085EwgIgy1gof6w8l8fxj30ng035wf6.jpg)

先通过逻辑地址，获取页号，以及页内偏移地址，再通过页号和物理地址的映射，算出实际的物理地址。

缺点：需要访问两次内存。

1.第一次是访问页表，获取实际的物理地址

2.通过该地址，进行存数或者取数

改进方法：**快表**

相当于cache，存放部分页表的内容。对应的，主存中的页表称为慢表。

从快表中读取可以加速访问速度。

###### 基于快表

![image](https://tvax4.sinaimg.cn/large/0085EwgIgy1gof79rs8pfj30j90a0mxr.jpg)



1.CPU给出逻辑地址，换算后得到页号。

2.首先在快表中查找是否有页号，有的话就能直接通过页框号和页内偏移量，算出物理地址。实现了只访存一次就能获取到物理地址

3.如果没命中，就需要到慢表中获取。获取后，需要将刚获取的页表存入到快表中，如果快表满了，就需要使用替换算法。

###### 二级页表

![image](https://tvax3.sinaimg.cn/large/0085EwgIgy1gof7a2w9sqj30k802i3yh.jpg)

![image](https://tva1.sinaimg.cn/large/0085EwgIgy1gof7aapso6j30l70ezdha.jpg)

在原来的基础上，在建立一层索引，用于对页表的映射。

作用：节约空间，也不用每次查找时需要从头到尾寻找页表项。



#### 分段存储

##### 基本分段存储管理

分页存储管理，提高了内存利用率，对用户透明；

分段存储管理，考虑了信息保护和共享，动态增长等，对程序员友好

分段存储管理：将用户进程分成几段，段内的内存必须是连续的，段间不需要是连续。

![image](https://tva2.sinaimg.cn/large/0085EwgIgy1gofotje19vj30a502daa2.jpg)

段表：

![image](https://tva1.sinaimg.cn/large/0085EwgIgy1gofou1ihf8j30ad01uq2v.jpg)



地址变换：

![image](https://tvax4.sinaimg.cn/large/0085EwgIgy1gofoudifexj30ei076wfd.jpg)

##### 段页式存储管理

将内存分成若干个段，段内按照分页存储管理，分成很多个页。

基本地址：

![image](https://tvax4.sinaimg.cn/large/0085EwgIgy1gofoxg5r32j30a501kdfs.jpg)



### 虚拟内存

#### 作用

​		分页和分段，都是需要一开始就要把作业全都加载到内存中，并且只有当作业结束时，才会把作业从内存中撤出。如果作业过于庞大，内存无法放入，则作业就无法运行；又因为作业在内存中有滞留性，如果遇到I/O请求而阻塞，就会长时间占有内存却不工作，降低了内存利用率和多道程序的并发性。

​		基于这种情况，引入了虚拟内存。

#### 局部性原理

##### 时间局部性

某条指令一旦执行，那么不久之后该指令会有很大的可能会继续执行。

##### 空间局部性

某个存储单元被访问了，那么不久过后它附近的存储单元也会被访问。典型例子：数组

#### 具体实现

##### 请求分页存储

基于分页存储。作业执行的时候，只在内存中加载部分的页面，在有需要时，通过请求调页来获取页面，通过页面置换把暂时不同的从内存中放入外存。

**1.存储结构**

![image](https://tva3.sinaimg.cn/large/0085EwgIgy1gofp93rg2yj30cq0213yk.jpg)



状态位：标记是否在内存中

访问字段：记录在一段时间内页面被访问的次数，页面置换算法会用到

修改位：标记进入内存后是否被修改

外存地址：指出该页在外存上的地址，也就是物理块号，供调入页面时参考

**2.缺页中断机制**

访问页面不存在时，会产生缺页中断，进而进入系统调用，让操作系统帮忙让请求的页面调入到内存中。

缺页中断属于内部中断，一条指令可能会引发多次缺页中断。

###### 页面置换算法

**-最佳置换算法**(OPT)

淘汰以后再也不会用到的页面。但是认识无法预知接下来需要的页面的，所以无法实现这个算法。

**-先进先出算法**(FIFO)

优先淘汰最早进入内存的。将页面号组成队列即可实现。会出现Belady

**Belady异常**：有可能分配的物理块增大了，但是缺页率不减反增。

**-最近最久未使用算法**(LRU)

选择最近最长时间未使用的页面进行淘汰

**-时钟置换算法**(CLOCK)

也叫做不是最近使用。Not Recently Use

##### 请求分段存储

##### 请求段页式存储

## 文件系统

### 文件保护

#### 口令

访问文件需要比对FCB中是否有该文件的正确口令

#### 加密

对文件内容加密，访问时有用户自行解密

#### 访问控制表

记录每个用户能对文件进行的操作类型。

### 文件共享

#### 软链接

将文件的索引存到用户的FCB中，使得用户通过就可以访问到文件。

访问速度较慢。

删除文件时，会将文件删除，其他FCB访问找不到该文件时，自动删除掉自己FCB中存的路径。

但是存在问题：当某用户删除了共享问价，而另一用户相同路径下创建的同名的文件，就会导致其他用户本应该删除掉自己的FCB索引内容，却访问了新创建的文件。

#### 硬链接

基于索引节点。索引节点中存入文件引用次数，有指向文件的指针。

而用户要实现文件共享，就在FCB中存有索引节点的指针。

删除文件时，只会把索引节点中的文件引用次数减一，这样才不会出现用户空指针的情况。 当引用次数位0，操作系统就会将文件删除。

### 磁盘结构

![image](https://tvax3.sinaimg.cn/large/0085EwgIgy1gofsaoi2a3j308r07sjrn.jpg)



**磁盘地址：柱面号·盘面号·扇区号**



![image](https://tvax1.sinaimg.cn/large/0085EwgIgy1gofsbrmeinj30b00aemxm.jpg)

### 磁盘调度算法

#### FCFS

先来先服务算法。

![image](https://tva4.sinaimg.cn/large/0085EwgIgy1gofseihfz4j30jy07w75b.jpg)



#### SSTF

最短寻找时间优先算法

![image](https://tvax2.sinaimg.cn/large/0085EwgIgy1gofsgbttvjj30j0061gme.jpg)

优先响应离磁头最近的请求。会导致饥饿，会出现可能频繁在某个区域附近写入而使得其他的请求无法得到满足。

#### SCAN

扫描算法。或者是电梯调度算法

![image](https://tva4.sinaimg.cn/large/0085EwgIgy1gofsi5rq24j30jq07g3zv.jpg)



改进版本的最短寻找时间优先算法。规定了方向。也就是说，会在当前的方向上寻找距离最短的请求进行响应。

#### C-SCAN

循环扫描算法

固定磁头单向移动。会达到磁道尽头又再返回。

![image](https://tva1.sinaimg.cn/large/0085EwgIgy1gofslh5tfkj30h604daa8.jpg)

改进：不需要达到磁道的尽头，达到最远的请求即可返回。

## I/O

### I/O控制方式

控制设备和处理及/内存的数据传送。

#### 程序直接控制

![image](https://tvax4.sinaimg.cn/large/0085EwgIgy1gofsqadkzyj306j0ahwew.jpg)

每次只读一个字的数据，CPU需要不断确认I/O状态。

未设置中断，导致CPU需要不断监控I/O设备是否已经完成读写。

缺点：只能串行输入。无法解决CPU和I/O读写之间速度差值过大的矛盾，导致CPU利用率低下。

#### 中断驱动控制

![image](https://tva1.sinaimg.cn/large/0085EwgIgy1gofstl0u5kj306o0ab3yy.jpg)

![image](https://tva1.sinaimg.cn/large/0085EwgIgy1gofsw1vv5tj30jq07ajth.jpg)

数据在存储器和I/O中传输都需要经过CPU的控制，会浪费时间。

#### DMA控制

![image](https://tvax1.sinaimg.cn/large/0085EwgIgy1gofsxso8m2j30dq06kwet.jpg)

引入DMA控制器，和IO、内存、CPU相连。CPU收到DMA的IO请求时，发送允许写入的指令，然后继续执行自己的作业。而DMA收到同意请求后，按字读取I/O输入到内存中。

优点：不需要像中断那样， 所有数据的写入都要经过CPU。

缺点：数据块较多并且离散的时候，需要发出多条指令

#### 通道控制

通道：一种硬件，类似于CPU.

执行过程：CPU要完成一组读写操作时，向通道发送相关信息：如要执行的程序的首地址，要访问的IO设备。接下来通道就通过这个任务清单，去完成CPU的任务。在数据传输结束时，发送一个中断给CPU，告诉CPU任务已完成。

通道相当于是秘书，CPU则是老板。

### I/O核心子系统

![image](https://tva3.sinaimg.cn/large/0085EwgIgy1goftd93a77j307x01smxi.jpg)

IO调度：确定响应IO请求的顺序

设备保护：类似于文件系统中的文件保护。

1.设备独立性软件

2.设备驱动软件

3.中断处理程序

### 假脱机技术(Spooling)

脱机技术：缓解CPU运行指令和IO读写速度相差过大的矛盾，将IO设备的数据传送在高速磁盘上。

![image](https://tvax2.sinaimg.cn/large/0085EwgIgy1goftjsxteyj30ef07ydhn.jpg)

![image](https://tvax3.sinaimg.cn/large/0085EwgIgy1goftl8yqunj30p70bodit.jpg)

### 设备分配

#### 分配策略

##### 静态分配

进程运行前，将所有所需资源全分给他，等运行结束后再将资源全部返回。

##### 动态分配

进程运行过程中动态的分配所需的资源。

#### 设备分配的数据结构

![image](https://tvax3.sinaimg.cn/large/0085EwgIgy1goftotrc20j30l90aztat.jpg)

##### 设备控制表(DCT)

记录设备的情况。

![image](https://tvax2.sinaimg.cn/large/0085EwgIgy1goftq9wgclj30ll078tdr.jpg)



##### 控制器控制表(COCT)

![image](https://tva3.sinaimg.cn/large/0085EwgIgy1goftr8i38tj30o50a4whj.jpg)

....不重要

#### 设备分配步骤

![image](https://tva4.sinaimg.cn/large/0085EwgIgy1goftse7nypj30nc0afn3f.jpg)



 

## 面经

### I/O多路复用

IO多路复用：

1.BIO：阻塞IO。

操作系统在使用read，write函数时，会一直等待IO的输入或读出，使程序处于挂起状态，阻塞掉其他程序，一直占用CPU资源。

2.NIO：非阻塞IO。用fcntl或者ioctl设为非阻塞模式。相当于是轮询。请求一次IO时，允许读的话，就立即返回数据，否则就返回错误。这样就能不阻塞其他的程序。但是轮询的开销会很大，依旧是需要不断地轮询来读取或者写入。

3.IO多路复用技术。使用一个线程来检查多个文件描述符(socke的状态)，调用select或者poll函数,当有文件描述符就绪的时候，就会在线程中进行IO的读写，否则就一直堵塞到超时。

4.AIO，异步非阻塞。发送请求，如果数据准备好了就返回，如果没有的话返回为准备好的信息，同时留下监听功能， 一直监听直到准备好后，通知请求来获取数据。这时请求就会继续发请求，从而取到数据。

**1.select，poll，epoll的区别？**

select：将所有的文件描述符都写入，但并不知道哪个请求能接收IO响应，只能轮询的查找所有的请求。时间复杂度为O(N)

poll：用链表来保存文件描述符，查找时依旧轮询的进行查找对应的文件描述符，时间复杂度为O(N)

epoll：sys_epoll_create中创建了eventpoll结构体。结构体有

就绪队列，存放就绪事件的描述符

红黑树，内核的时间表，收集文件描述符。每个新的事件都会被挂到红黑树上。

epoll的事件和驱动程序建立了回调关系，事件发生的时候，会将事件放入就绪队列中。

当epoll检查是否有事件发生，只需要检查就绪队列中是否有元素即可，非空的话就把事件复制到用户态，空的话就一直等待到超时。

epoll的工作模式：www.qguizhan

1.ET：边缘触发模式。有事件描述符的数据没读取完，那么下次epoll_wait在读取时就找不到这个描述符中的数据了

2.LT：水平触发模式：同理，下次epoll_wait()还能读取到该数据。

综上所述，epoll是实现了O(1)的查找响应文件描述符。